{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import models\n",
    "import matplotlib.pylab as plt\n",
    "DATAS_UP_PATH='./output_up_camera/'\n",
    "DATAS_DOWN_PATH='./output_down_camera/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_list = os.listdir(DATAS_UP_PATH)\n",
    "donw_list = os.listdir(DATAS_DOWN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=list()\n",
    "train_list=donw_list\n",
    "PATH = DATAS_DOWN_PATH\n",
    "# 0.4~ 0.6 / ~0.4 / 0.6~\n",
    "for file_name in train_list:\n",
    "    if file_name[-4:] != '.png':continue    \n",
    "    x = float(file_name.split('_')[1])\n",
    "    if x >0.45 and x <0.55:\n",
    "        label = torch.from_numpy(np.array([1,0,0]))\n",
    "    elif x <= 0.45:\n",
    "        label = torch.from_numpy(np.array([0,1,0]))\n",
    "    else:\n",
    "        label = torch.from_numpy(np.array([0,0,1]))\n",
    "    img = cv2.imread(PATH+file_name)\n",
    "    img = img.reshape(3,224,224)\n",
    "    dataset.append((img, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RATE = 0.2\n",
    "BATCH_SIZE = 8\n",
    "TEST_SET_NUM = int(len(dataset)*TEST_RATE)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - TEST_SET_NUM, TEST_SET_NUM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "#     num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "#     num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoDrive(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.output_classes=3 # position_bool, people, x, y\n",
    "        self.model_up = self.making_transfer_model1()\n",
    "\n",
    "    \n",
    "    def making_transfer_model1(self):\n",
    "        model = models.alexnet(pretrained=True)       \n",
    "        model.classifier=torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.5, inplace=True),\n",
    "            torch.nn.Linear(9216, self.output_classes),\n",
    "            torch.nn.Softmax(-1),\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "#     def making_transfer_model2(self):\n",
    "#         model = models.squeezenet1_0(pretrained=True)\n",
    "#         model.classifier=torch.nn.Sequential(\n",
    "# #             torch.nn.Dropout(p=0.5, inplace=True),\n",
    "# #             torch.nn.Linear(in_features=212992, out_features=self.unit_output, bias=True),\n",
    "# #             torch.nn.Mish(),\n",
    "#             torch.nn.Dropout(p=0.5, inplace=True),\n",
    "#             torch.nn.Conv2d(512, self.unit_output, kernel_size=(1,1), stride=(1,1)),\n",
    "#             torch.nn.ReLU(True),\n",
    "#             torch.nn.AdaptiveAvgPool2d(output_size=(1,1)),\n",
    "#             torch.nn.Flatten()\n",
    "#         )\n",
    "#         return model\n",
    "\n",
    "    def forward(self, up_img): # follow / to_position / line_num / loaded\n",
    "        # up_img = torch.from_numpy(up_img).float()\n",
    "        # down_img = torch.from_numpy(down_img).float()\n",
    "        x_up = self.model_up(up_img)\n",
    "        # x_down = self.model_down(down_img)\n",
    "        # follow = follow.unsqueeze(-1)\n",
    "        # to_position = to_position.unsqueeze(-1)\n",
    "        # line_num = line_num.unsqueeze(-1)\n",
    "        # loaded = loaded.unsqueeze(-1)\n",
    "        # x = torch.cat([follow,to_position, line_num, loaded, x_up, x_down], dim=-1)\n",
    "        # x = self.determine_model(x.float())\n",
    "        return x_up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "auto = AutoDrive()\n",
    "auto = auto.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 TRAIN_LOSS 0.07823362239140016 TEST LOSS 0.0170381672187538 ACC: 0.5797665369649806\n",
      "42 15    154 209    61 33\n",
      "1 TRAIN_LOSS 0.06702287280605924 TEST LOSS 0.0175990130650858 ACC: 0.5953307392996109\n",
      "42 7    154 243    61 7\n",
      "2 TRAIN_LOSS 0.06542484120172286 TEST LOSS 0.014930764061003807 ACC: 0.6342412451361867\n",
      "42 9    154 221    61 27\n",
      "3 TRAIN_LOSS 0.061324824618922136 TEST LOSS 0.015847319294970325 ACC: 0.6381322957198443\n",
      "42 24    154 211    61 22\n",
      "4 TRAIN_LOSS 0.058771415443271975 TEST LOSS 0.015762199223737308 ACC: 0.6108949416342413\n",
      "42 43    154 170    61 44\n",
      "5 TRAIN_LOSS 0.05809696360784746 TEST LOSS 0.014651308727635483 ACC: 0.6575875486381323\n",
      "42 47    154 185    61 25\n",
      "6 TRAIN_LOSS 0.05342998578854572 TEST LOSS 0.015991641389720635 ACC: 0.6186770428015564\n",
      "42 37    154 203    61 17\n",
      "7 TRAIN_LOSS 0.04792884722757896 TEST LOSS 0.015260975648456973 ACC: 0.6381322957198443\n",
      "42 76    154 156    61 25\n",
      "8 TRAIN_LOSS 0.042429534377754895 TEST LOSS 0.013239240831902055 ACC: 0.6653696498054474\n",
      "42 61    154 163    61 33\n",
      "9 TRAIN_LOSS 0.044147086978422526 TEST LOSS 0.011113164025985778 ACC: 0.7120622568093385\n",
      "42 46    154 154    61 57\n",
      "10 TRAIN_LOSS 0.04062806585883352 TEST LOSS 0.010118427907446478 ACC: 0.7431906614785992\n",
      "42 46    154 177    61 34\n",
      "11 TRAIN_LOSS 0.037431490560449976 TEST LOSS 0.013052702877771993 ACC: 0.7003891050583657\n",
      "42 21    154 216    61 20\n",
      "12 TRAIN_LOSS 0.03787225508040491 TEST LOSS 0.010155092417498042 ACC: 0.7431906614785992\n",
      "42 52    154 159    61 46\n",
      "13 TRAIN_LOSS 0.03336945025373526 TEST LOSS 0.010190491546452742 ACC: 0.7587548638132295\n",
      "42 51    154 154    61 52\n",
      "14 TRAIN_LOSS 0.030718367387348577 TEST LOSS 0.008081731165429498 ACC: 0.7821011673151751\n",
      "42 37    154 162    61 58\n",
      "15 TRAIN_LOSS 0.030082346400398224 TEST LOSS 0.007089091646068291 ACC: 0.8210116731517509\n",
      "42 49    154 161    61 47\n",
      "16 TRAIN_LOSS 0.03106070863597588 TEST LOSS 0.008965090554975814 ACC: 0.7704280155642024\n",
      "42 43    154 143    61 71\n",
      "17 TRAIN_LOSS 0.028289173363711582 TEST LOSS 0.007210002335129081 ACC: 0.8210116731517509\n",
      "42 39    154 169    61 49\n",
      "18 TRAIN_LOSS 0.028168828570889128 TEST LOSS 0.008789700756740942 ACC: 0.77431906614786\n",
      "42 41    154 187    61 29\n",
      "19 TRAIN_LOSS 0.026888669232913956 TEST LOSS 0.007246502642501653 ACC: 0.8171206225680934\n",
      "42 40    154 161    61 56\n",
      "20 TRAIN_LOSS 0.023811969311784677 TEST LOSS 0.00789611812695455 ACC: 0.8054474708171206\n",
      "42 57    154 151    61 49\n",
      "21 TRAIN_LOSS 0.02234594738437044 TEST LOSS 0.007179349776835757 ACC: 0.8171206225680934\n",
      "42 35    154 150    61 72\n",
      "22 TRAIN_LOSS 0.023448274293298387 TEST LOSS 0.007445334460484843 ACC: 0.8054474708171206\n",
      "42 33    154 160    61 64\n",
      "23 TRAIN_LOSS 0.021483747875644076 TEST LOSS 0.007933678793999935 ACC: 0.8015564202334631\n",
      "42 32    154 182    61 43\n",
      "24 TRAIN_LOSS 0.020851912665459896 TEST LOSS 0.006769329657350533 ACC: 0.8287937743190662\n",
      "42 44    154 157    61 56\n",
      "25 TRAIN_LOSS 0.020420796212519188 TEST LOSS 0.006909303628053183 ACC: 0.8171206225680934\n",
      "42 55    154 149    61 53\n",
      "26 TRAIN_LOSS 0.02027680252312686 TEST LOSS 0.007170434591835111 ACC: 0.8210116731517509\n",
      "42 42    154 169    61 46\n",
      "27 TRAIN_LOSS 0.016218393229324994 TEST LOSS 0.00797035072564151 ACC: 0.7976653696498055\n",
      "42 57    154 137    61 63\n",
      "28 TRAIN_LOSS 0.01903681068568842 TEST LOSS 0.0065757541804925945 ACC: 0.8365758754863813\n",
      "42 44    154 165    61 48\n",
      "29 TRAIN_LOSS 0.01963869792478094 TEST LOSS 0.007654845482644404 ACC: 0.8249027237354085\n",
      "42 43    154 157    61 57\n",
      "30 TRAIN_LOSS 0.01651038270052305 TEST LOSS 0.005725635164906542 ACC: 0.8638132295719845\n",
      "42 39    154 162    61 56\n",
      "31 TRAIN_LOSS 0.017676199456597118 TEST LOSS 0.007662710048809126 ACC: 0.8287937743190662\n",
      "42 30    154 175    61 52\n",
      "32 TRAIN_LOSS 0.01621118872082187 TEST LOSS 0.006055151442145559 ACC: 0.8443579766536965\n",
      "42 45    154 152    61 60\n",
      "33 TRAIN_LOSS 0.01792140879055869 TEST LOSS 0.005391579657677083 ACC: 0.8599221789883269\n",
      "42 42    154 156    61 59\n",
      "34 TRAIN_LOSS 0.017236201215810813 TEST LOSS 0.006770370535349568 ACC: 0.8560311284046692\n",
      "42 30    154 169    61 58\n",
      "35 TRAIN_LOSS 0.014014028853479526 TEST LOSS 0.005674279617428316 ACC: 0.8560311284046692\n",
      "42 49    154 153    61 55\n",
      "36 TRAIN_LOSS 0.014644474370934156 TEST LOSS 0.005408805631941858 ACC: 0.8599221789883269\n",
      "42 42    154 160    61 55\n",
      "37 TRAIN_LOSS 0.013893265668520205 TEST LOSS 0.00587820079076151 ACC: 0.8443579766536965\n",
      "42 49    154 158    61 50\n",
      "38 TRAIN_LOSS 0.015499572345718799 TEST LOSS 0.005438464624872468 ACC: 0.8599221789883269\n",
      "42 42    154 164    61 51\n",
      "39 TRAIN_LOSS 0.015102292777035486 TEST LOSS 0.005267111243904796 ACC: 0.8638132295719845\n",
      "42 39    154 163    61 55\n",
      "40 TRAIN_LOSS 0.012409026520725354 TEST LOSS 0.005684578001267251 ACC: 0.8521400778210116\n",
      "42 41    154 164    61 52\n",
      "41 TRAIN_LOSS 0.012785053438713579 TEST LOSS 0.005458796534556823 ACC: 0.8599221789883269\n",
      "42 45    154 160    61 52\n",
      "42 TRAIN_LOSS 0.012400542715644095 TEST LOSS 0.005328682146183711 ACC: 0.8715953307392996\n",
      "42 39    154 157    61 61\n",
      "43 TRAIN_LOSS 0.012251608102701981 TEST LOSS 0.004494073326021781 ACC: 0.8871595330739299\n",
      "42 37    154 158    61 62\n",
      "44 TRAIN_LOSS 0.013462625125038949 TEST LOSS 0.004692219574627709 ACC: 0.8832684824902723\n",
      "42 37    154 157    61 63\n",
      "45 TRAIN_LOSS 0.011484230538750436 TEST LOSS 0.00562343987045585 ACC: 0.8521400778210116\n",
      "42 35    154 169    61 53\n",
      "46 TRAIN_LOSS 0.01273512098111995 TEST LOSS 0.005010339072706171 ACC: 0.8754863813229572\n",
      "42 35    154 166    61 56\n",
      "47 TRAIN_LOSS 0.012201726668539678 TEST LOSS 0.005178197348628063 ACC: 0.867704280155642\n",
      "42 39    154 154    61 64\n",
      "48 TRAIN_LOSS 0.010902406640553752 TEST LOSS 0.004916465699904624 ACC: 0.8715953307392996\n",
      "42 44    154 155    61 58\n",
      "49 TRAIN_LOSS 0.01157105943108347 TEST LOSS 0.005693792832964589 ACC: 0.8560311284046692\n",
      "42 43    154 155    61 59\n",
      "50 TRAIN_LOSS 0.010320930629388832 TEST LOSS 0.005879022268005846 ACC: 0.8482490272373541\n",
      "42 34    154 167    61 56\n",
      "51 TRAIN_LOSS 0.010681048441489847 TEST LOSS 0.005246838706940529 ACC: 0.8715953307392996\n",
      "42 35    154 168    61 54\n",
      "52 TRAIN_LOSS 0.01086491555091472 TEST LOSS 0.005548105629501639 ACC: 0.8638132295719845\n",
      "42 33    154 166    61 58\n",
      "53 TRAIN_LOSS 0.010737240082558955 TEST LOSS 0.005757824920030883 ACC: 0.8638132295719845\n",
      "42 35    154 163    61 59\n",
      "54 TRAIN_LOSS 0.00981547674780226 TEST LOSS 0.00519822172617634 ACC: 0.867704280155642\n",
      "42 37    154 164    61 56\n",
      "55 TRAIN_LOSS 0.009833860026259366 TEST LOSS 0.005153569729875498 ACC: 0.867704280155642\n",
      "42 42    154 155    61 60\n",
      "56 TRAIN_LOSS 0.00973720402105309 TEST LOSS 0.005933029642364859 ACC: 0.8715953307392996\n",
      "42 43    154 156    61 58\n",
      "57 TRAIN_LOSS 0.008853230494933369 TEST LOSS 0.004836805599672785 ACC: 0.8793774319066148\n",
      "42 37    154 162    61 58\n",
      "58 TRAIN_LOSS 0.009439462817596554 TEST LOSS 0.004360905881057918 ACC: 0.8832684824902723\n",
      "42 32    154 165    61 60\n",
      "59 TRAIN_LOSS 0.009240369388565478 TEST LOSS 0.006488918330418925 ACC: 0.8638132295719845\n",
      "42 36    154 166    61 55\n",
      "60 TRAIN_LOSS 0.008548483310506502 TEST LOSS 0.0065656673119689705 ACC: 0.8599221789883269\n",
      "42 40    154 159    61 58\n",
      "61 TRAIN_LOSS 0.009018098333930228 TEST LOSS 0.006192460598184905 ACC: 0.8793774319066148\n",
      "42 44    154 161    61 52\n",
      "62 TRAIN_LOSS 0.008690767251100058 TEST LOSS 0.005035672206359151 ACC: 0.8638132295719845\n",
      "42 35    154 165    61 57\n",
      "63 TRAIN_LOSS 0.008800376713971684 TEST LOSS 0.005850608710648949 ACC: 0.8482490272373541\n",
      "42 52    154 156    61 49\n",
      "64 TRAIN_LOSS 0.008380452018767479 TEST LOSS 0.005494155308615837 ACC: 0.8521400778210116\n",
      "42 50    154 151    61 56\n",
      "65 TRAIN_LOSS 0.008300961223557765 TEST LOSS 0.004837769014826081 ACC: 0.8754863813229572\n",
      "42 45    154 154    61 58\n",
      "66 TRAIN_LOSS 0.00734657165141421 TEST LOSS 0.005058053866434654 ACC: 0.8715953307392996\n",
      "42 39    154 158    61 60\n",
      "67 TRAIN_LOSS 0.007443786131268809 TEST LOSS 0.004131373264446333 ACC: 0.8910505836575876\n",
      "42 42    154 160    61 55\n",
      "68 TRAIN_LOSS 0.008207429707746098 TEST LOSS 0.006026349642861214 ACC: 0.8793774319066148\n",
      "42 41    154 161    61 55\n",
      "69 TRAIN_LOSS 0.007412544020418991 TEST LOSS 0.006333801996847071 ACC: 0.8638132295719845\n",
      "42 48    154 153    61 56\n",
      "70 TRAIN_LOSS 0.009095103824185026 TEST LOSS 0.004566561851056169 ACC: 0.8910505836575876\n",
      "42 36    154 162    61 59\n",
      "71 TRAIN_LOSS 0.007459242056315975 TEST LOSS 0.005544097507046354 ACC: 0.8832684824902723\n",
      "42 47    154 159    61 51\n",
      "72 TRAIN_LOSS 0.007647315815728926 TEST LOSS 0.005437941402776696 ACC: 0.8910505836575876\n",
      "42 40    154 159    61 58\n",
      "73 TRAIN_LOSS 0.007624119172300346 TEST LOSS 0.004783623413353115 ACC: 0.8793774319066148\n",
      "42 48    154 160    61 49\n",
      "74 TRAIN_LOSS 0.006370758732005316 TEST LOSS 0.004636767309463442 ACC: 0.8715953307392996\n",
      "42 37    154 161    61 59\n",
      "75 TRAIN_LOSS 0.006583253233349277 TEST LOSS 0.004167691279014261 ACC: 0.8910505836575876\n",
      "42 41    154 158    61 58\n",
      "76 TRAIN_LOSS 0.006694089577819587 TEST LOSS 0.004930468384857772 ACC: 0.8754863813229572\n",
      "42 41    154 160    61 56\n",
      "77 TRAIN_LOSS 0.005727967399567482 TEST LOSS 0.005132693261024089 ACC: 0.867704280155642\n",
      "42 36    154 169    61 52\n",
      "78 TRAIN_LOSS 0.0062603978331450824 TEST LOSS 0.004102101121895044 ACC: 0.8949416342412452\n",
      "42 40    154 163    61 54\n",
      "79 TRAIN_LOSS 0.007076452214430279 TEST LOSS 0.00493158301490754 ACC: 0.8754863813229572\n",
      "42 40    154 157    61 60\n",
      "80 TRAIN_LOSS 0.007137355173608208 TEST LOSS 0.004489047981885621 ACC: 0.8871595330739299\n",
      "42 42    154 161    61 54\n",
      "81 TRAIN_LOSS 0.006774201931192717 TEST LOSS 0.004369921721373087 ACC: 0.8910505836575876\n",
      "42 36    154 164    61 57\n",
      "82 TRAIN_LOSS 0.006166769372813897 TEST LOSS 0.005328076358899069 ACC: 0.8638132295719845\n",
      "42 41    154 163    61 53\n",
      "83 TRAIN_LOSS 0.005990625355494161 TEST LOSS 0.004642492138458133 ACC: 0.8832684824902723\n",
      "42 45    154 157    61 55\n",
      "84 TRAIN_LOSS 0.006997767125586128 TEST LOSS 0.0054724021644443855 ACC: 0.8599221789883269\n",
      "42 35    154 169    61 53\n",
      "85 TRAIN_LOSS 0.0056180995725936 TEST LOSS 0.004657361294045059 ACC: 0.8832684824902723\n",
      "42 39    154 163    61 55\n",
      "86 TRAIN_LOSS 0.006040238220867944 TEST LOSS 0.005056212848262564 ACC: 0.8793774319066148\n",
      "42 38    154 163    61 56\n",
      "87 TRAIN_LOSS 0.006855803704911169 TEST LOSS 0.004064043672168301 ACC: 0.8949416342412452\n",
      "42 42    154 155    61 60\n",
      "88 TRAIN_LOSS 0.005673710010394976 TEST LOSS 0.00523954235626102 ACC: 0.867704280155642\n",
      "42 46    154 159    61 52\n",
      "89 TRAIN_LOSS 0.0063307039468668775 TEST LOSS 0.00455972981360172 ACC: 0.8793774319066148\n",
      "42 39    154 159    61 59\n",
      "90 TRAIN_LOSS 0.005912857296865738 TEST LOSS 0.0046273451370951735 ACC: 0.8871595330739299\n",
      "42 33    154 167    61 57\n",
      "91 TRAIN_LOSS 0.005827631931824443 TEST LOSS 0.0045850086768777455 ACC: 0.8754863813229572\n",
      "42 38    154 158    61 61\n",
      "92 TRAIN_LOSS 0.0053222170135854285 TEST LOSS 0.004777375826112027 ACC: 0.8793774319066148\n",
      "42 37    154 165    61 55\n",
      "93 TRAIN_LOSS 0.00580909883001899 TEST LOSS 0.004916541771202236 ACC: 0.867704280155642\n",
      "42 38    154 161    61 58\n",
      "94 TRAIN_LOSS 0.005490194034947496 TEST LOSS 0.004764264195809568 ACC: 0.8832684824902723\n",
      "42 42    154 159    61 56\n",
      "95 TRAIN_LOSS 0.005544450032571874 TEST LOSS 0.005315071413953017 ACC: 0.8599221789883269\n",
      "42 37    154 151    61 69\n",
      "96 TRAIN_LOSS 0.0053519460477717655 TEST LOSS 0.004945738770154664 ACC: 0.8754863813229572\n",
      "42 40    154 160    61 57\n",
      "97 TRAIN_LOSS 0.005494331107529221 TEST LOSS 0.004823794160835474 ACC: 0.8754863813229572\n",
      "42 42    154 156    61 59\n",
      "98 TRAIN_LOSS 0.005711996601713306 TEST LOSS 0.004905969252382271 ACC: 0.8715953307392996\n",
      "42 40    154 158    61 59\n",
      "99 TRAIN_LOSS 0.005028585515597451 TEST LOSS 0.004589941251138769 ACC: 0.8871595330739299\n",
      "42 36    154 164    61 57\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_EPOCHS=100\n",
    "optimizer = torch.optim.Adam(auto.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9), weight_decay=0.0005)\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "BEST_MODEL_PATH = 'best_model_down.pth'\n",
    "\n",
    "criterion = torch.nn.SmoothL1Loss()\n",
    "\n",
    "d_time = datetime.datetime.now()\n",
    "folder_name = \"runs/\"+d_time.strftime(\"%Y%m%d%H%M%S\")\n",
    "os.mkdir(folder_name)\n",
    "writer = SummaryWriter(log_dir=folder_name)\n",
    "pre_test_loss = 10.\n",
    "EARLY_BIRD = 0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss=0.\n",
    "    test_loss=0.\n",
    "#     auto.train()\n",
    "    for up_img,labels in train_loader:\n",
    "#         print(up_img)\n",
    "#         up_img = normalize(up_img.float()).to(device=device)\n",
    "        up_img = up_img.float().to(device=device)\n",
    "        labels=labels.to(device);                \n",
    "        optimizer.zero_grad()\n",
    "        outputs = auto(up_img.float())\n",
    "#         print(\"outputs: \",outputs[-1], \"labels: \", labels[-1])\n",
    "#         loss = F.cross_entropy(outputs, labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss+=loss        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         scaler.scale(loss).backward()\n",
    "#         scaler.step(optimizer)\n",
    "#         scaler.update()\n",
    "        \n",
    "    \n",
    "    acc = 0.\n",
    "    acc0=acc1=acc2=0\n",
    "    count0=count1=count2=0\n",
    "    with torch.no_grad():\n",
    "        for up_img,labels in test_loader:\n",
    "#             up_img = normalize(up_img.float()).to(device=device);\n",
    "            up_img = up_img.float().to(device=device)\n",
    "            labels=labels.to(device);        1        \n",
    "            outputs = auto(up_img.float())\n",
    "    #         loss_position = F.cross_entropy(outputs[:,0], position_bool)\n",
    "    #         loss_people = F.cross_entropy(outputs[:,1], people)\n",
    "    #         loss_x = F.cross_entropy(outputs[:,2], x)\n",
    "    #         loss_y = F.cross_entropy(outputs[:,3], y)\n",
    "            loss =criterion(outputs, labels)\n",
    "            acc0 += sum(labels.argmax(-1)==0)\n",
    "            acc1 += sum(labels.argmax(-1)==1)\n",
    "            acc2 += sum(labels.argmax(-1)==2)\n",
    "            count0 += sum(outputs.argmax(-1)==0)\n",
    "            count1 += sum(outputs.argmax(-1)==1)\n",
    "            count2 += sum(outputs.argmax(-1)==2)\n",
    "                \n",
    "            acc += sum(outputs.argmax(-1)==labels.argmax(-1))\n",
    "            test_loss+=loss\n",
    "            \n",
    "#             print(\"outputs: \",outputs)\n",
    "#     print(f\"{epoch} TRAIN_LOSS: {train_loss.item()} TEST LOSS: {test_loss.item()}\")\n",
    "    writer.add_scalar(\"TRAIN_LOSS\",train_loss.item()/len(train_loader),epoch)\n",
    "    writer.add_scalar(\"TEST LOSS\",test_loss.item()/len(test_loader),epoch)\n",
    "    print(epoch, \"TRAIN_LOSS\",train_loss.item()/len(test_dataset),\"TEST LOSS\",test_loss.item()/len(test_dataset), 'ACC:', acc.item()/len(test_dataset))\n",
    "    print(acc0.item(),count0.item(),\"  \", acc1.item(), count1.item(), \"  \", acc2.item(), count2.item())\n",
    "   \n",
    "#     print(\"outputs: \",outputs[-1], \"labels: \", labels[-1])\n",
    "    \n",
    "    if pre_test_loss>test_loss and epoch>50:\n",
    "        pre_test_loss= test_loss\n",
    "        torch.save(auto.state_dict(), BEST_MODEL_PATH)\n",
    "    if pre_test_loss<test_loss and epoch>50:\n",
    "        EARLY_BIRD +=1\n",
    "        if EARLY_BIRD >100:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33b0c032e04388c0be1572b4c64e4f6e2fa9cda7ba5f9f285430d52a126a80b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('datavenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
