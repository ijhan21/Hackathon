{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import models\n",
    "import matplotlib.pylab as plt\n",
    "DATAS_UP_PATH='./output_up_camera/'\n",
    "DATAS_DOWN_PATH='./output_down_camera/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_list = os.listdir(DATAS_UP_PATH)\n",
    "donw_list = os.listdir(DATAS_DOWN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=list()\n",
    "train_list=donw_list\n",
    "PATH = DATAS_DOWN_PATH\n",
    "# 0.4~ 0.6 / ~0.4 / 0.6~\n",
    "for file_name in train_list:\n",
    "    if file_name[-4:] != '.png':continue    \n",
    "    x = float(file_name.split('_')[1])\n",
    "    if x >0.45 and x <0.55:\n",
    "        label = torch.from_numpy(np.array([1,0,0]))\n",
    "    elif x <= 0.45:\n",
    "        label = torch.from_numpy(np.array([0,1,0]))\n",
    "    else:\n",
    "        label = torch.from_numpy(np.array([0,0,1]))\n",
    "    img = cv2.imread(PATH+file_name)\n",
    "    img = img.reshape(3,224,224)\n",
    "    dataset.append((img, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RATE = 0.2\n",
    "BATCH_SIZE = 1\n",
    "TEST_SET_NUM = int(len(dataset)*TEST_RATE)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - TEST_SET_NUM, TEST_SET_NUM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "#     num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "#     num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoDrive(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.output_classes=3 # position_bool, people, x, y\n",
    "        self.model_up = self.making_transfer_model1()\n",
    "\n",
    "    \n",
    "    def making_transfer_model1(self):\n",
    "        model = models.efficientnet_b0(pretrained=True)       \n",
    "        model.classifier=torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.5, inplace=True),\n",
    "            torch.nn.Linear(9216, self.output_classes),\n",
    "            torch.nn.Softmax(-1),\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "#     def making_transfer_model2(self):\n",
    "#         model = models.squeezenet1_0(pretrained=True)\n",
    "#         model.classifier=torch.nn.Sequential(\n",
    "# #             torch.nn.Dropout(p=0.5, inplace=True),\n",
    "# #             torch.nn.Linear(in_features=212992, out_features=self.unit_output, bias=True),\n",
    "# #             torch.nn.Mish(),\n",
    "#             torch.nn.Dropout(p=0.5, inplace=True),\n",
    "#             torch.nn.Conv2d(512, self.unit_output, kernel_size=(1,1), stride=(1,1)),\n",
    "#             torch.nn.ReLU(True),\n",
    "#             torch.nn.AdaptiveAvgPool2d(output_size=(1,1)),\n",
    "#             torch.nn.Flatten()\n",
    "#         )\n",
    "#         return model\n",
    "\n",
    "    def forward(self, up_img): # follow / to_position / line_num / loaded\n",
    "        # up_img = torch.from_numpy(up_img).float()\n",
    "        # down_img = torch.from_numpy(down_img).float()\n",
    "        x_up = self.model_up(up_img)\n",
    "        # x_down = self.model_down(down_img)\n",
    "        # follow = follow.unsqueeze(-1)\n",
    "        # to_position = to_position.unsqueeze(-1)\n",
    "        # line_num = line_num.unsqueeze(-1)\n",
    "        # loaded = loaded.unsqueeze(-1)\n",
    "        # x = torch.cat([follow,to_position, line_num, loaded, x_up, x_down], dim=-1)\n",
    "        # x = self.determine_model(x.float())\n",
    "        return x_up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21474/1955526729.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mauto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoDrive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mauto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/VENV/datavenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/VENV/datavenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/VENV/datavenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/VENV/datavenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/VENV/datavenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/VENV/datavenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/VENV/datavenv/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    896\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "auto = AutoDrive()\n",
    "auto = auto.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 TRAIN_LOSS 0.07823362239140016 TEST LOSS 0.0170381672187538 ACC: 0.5797665369649806\n",
      "42 15    154 209    61 33\n",
      "1 TRAIN_LOSS 0.06702287280605924 TEST LOSS 0.0175990130650858 ACC: 0.5953307392996109\n",
      "42 7    154 243    61 7\n",
      "2 TRAIN_LOSS 0.06542484120172286 TEST LOSS 0.014930764061003807 ACC: 0.6342412451361867\n",
      "42 9    154 221    61 27\n",
      "3 TRAIN_LOSS 0.061324824618922136 TEST LOSS 0.015847319294970325 ACC: 0.6381322957198443\n",
      "42 24    154 211    61 22\n",
      "4 TRAIN_LOSS 0.058771415443271975 TEST LOSS 0.015762199223737308 ACC: 0.6108949416342413\n",
      "42 43    154 170    61 44\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_EPOCHS=100\n",
    "optimizer = torch.optim.Adam(auto.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9), weight_decay=0.0005)\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "BEST_MODEL_PATH = 'best_model_efficient_down.pth'\n",
    "\n",
    "criterion = torch.nn.SmoothL1Loss()\n",
    "\n",
    "d_time = datetime.datetime.now()\n",
    "folder_name = \"runs/\"+d_time.strftime(\"%Y%m%d%H%M%S\")\n",
    "os.mkdir(folder_name)\n",
    "writer = SummaryWriter(log_dir=folder_name)\n",
    "pre_test_loss = 10.\n",
    "EARLY_BIRD = 0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss=0.\n",
    "    test_loss=0.\n",
    "#     auto.train()\n",
    "    for up_img,labels in train_loader:\n",
    "#         print(up_img)\n",
    "#         up_img = normalize(up_img.float()).to(device=device)\n",
    "        up_img = up_img.float().to(device=device)\n",
    "        labels=labels.to(device);                \n",
    "        optimizer.zero_grad()\n",
    "        outputs = auto(up_img.float())\n",
    "#         print(\"outputs: \",outputs[-1], \"labels: \", labels[-1])\n",
    "#         loss = F.cross_entropy(outputs, labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss+=loss        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         scaler.scale(loss).backward()\n",
    "#         scaler.step(optimizer)\n",
    "#         scaler.update()\n",
    "        \n",
    "    \n",
    "    acc = 0.\n",
    "    acc0=acc1=acc2=0\n",
    "    count0=count1=count2=0\n",
    "    with torch.no_grad():\n",
    "        for up_img,labels in test_loader:\n",
    "#             up_img = normalize(up_img.float()).to(device=device);\n",
    "            up_img = up_img.float().to(device=device)\n",
    "            labels=labels.to(device);        1        \n",
    "            outputs = auto(up_img.float())\n",
    "    #         loss_position = F.cross_entropy(outputs[:,0], position_bool)\n",
    "    #         loss_people = F.cross_entropy(outputs[:,1], people)\n",
    "    #         loss_x = F.cross_entropy(outputs[:,2], x)\n",
    "    #         loss_y = F.cross_entropy(outputs[:,3], y)\n",
    "            loss =criterion(outputs, labels)\n",
    "            acc0 += sum(labels.argmax(-1)==0)\n",
    "            acc1 += sum(labels.argmax(-1)==1)\n",
    "            acc2 += sum(labels.argmax(-1)==2)\n",
    "            count0 += sum(outputs.argmax(-1)==0)\n",
    "            count1 += sum(outputs.argmax(-1)==1)\n",
    "            count2 += sum(outputs.argmax(-1)==2)\n",
    "                \n",
    "            acc += sum(outputs.argmax(-1)==labels.argmax(-1))\n",
    "            test_loss+=loss\n",
    "            \n",
    "#             print(\"outputs: \",outputs)\n",
    "#     print(f\"{epoch} TRAIN_LOSS: {train_loss.item()} TEST LOSS: {test_loss.item()}\")\n",
    "    writer.add_scalar(\"TRAIN_LOSS\",train_loss.item()/len(train_loader),epoch)\n",
    "    writer.add_scalar(\"TEST LOSS\",test_loss.item()/len(test_loader),epoch)\n",
    "    print(epoch, \"TRAIN_LOSS\",train_loss.item()/len(test_dataset),\"TEST LOSS\",test_loss.item()/len(test_dataset), 'ACC:', acc.item()/len(test_dataset))\n",
    "    print(acc0.item(),count0.item(),\"  \", acc1.item(), count1.item(), \"  \", acc2.item(), count2.item())\n",
    "   \n",
    "#     print(\"outputs: \",outputs[-1], \"labels: \", labels[-1])\n",
    "    \n",
    "    if pre_test_loss>test_loss and epoch>50:\n",
    "        pre_test_loss= test_loss\n",
    "        torch.save(auto.state_dict(), BEST_MODEL_PATH)\n",
    "    if pre_test_loss<test_loss and epoch>50:\n",
    "        EARLY_BIRD +=1\n",
    "        if EARLY_BIRD >100:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33b0c032e04388c0be1572b4c64e4f6e2fa9cda7ba5f9f285430d52a126a80b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('datavenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
