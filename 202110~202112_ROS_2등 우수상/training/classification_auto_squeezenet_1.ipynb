{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "DATAS_UP_PATH='./output_up_camera/'\n",
    "DATAS_DOWN_PATH='./output_down_camera/'\n",
    "DATAS_STOP = './output_down_camera_stop_people/'\n",
    "DATAS_NVIDIA = '/output_down_camera_stop_people/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_list = os.listdir(DATAS_UP_PATH)\n",
    "donw_list = os.listdir(DATAS_DOWN_PATH)\n",
    "stop_list=os.listdir(DATAS_STOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=list()\n",
    "train_list=donw_list\n",
    "PATH = DATAS_DOWN_PATH\n",
    "# 0.4~ 0.6 / ~0.4 / 0.6~\n",
    "CLASSES_NUM = 4 # go, left, right, people\n",
    "label_vector = np.eye(CLASSES_NUM)\n",
    "for file_name in train_list:\n",
    "    if file_name[-4:] != '.png':continue    \n",
    "    img = cv2.imread(PATH+file_name)\n",
    "    img = img.reshape(3,224,224)\n",
    "    x = float(file_name.split('_')[1])\n",
    "    if x >0.45 and x <0.55:\n",
    "        label = torch.from_numpy(label_vector[0])\n",
    "        dataset.append((img, label))\n",
    "\n",
    "    elif x <= 0.45:\n",
    "        label = torch.from_numpy(label_vector[1])\n",
    "        dataset.append((img, label))\n",
    "        label_c = torch.from_numpy(label_vector[2])\n",
    "        img_c = img.copy()\n",
    "        img_c = cv2.flip(img_c,-1)\n",
    "        dataset.append((img_c, label_c))\n",
    "    else:\n",
    "        label = torch.from_numpy(label_vector[2])\n",
    "        dataset.append((img, label))\n",
    "        label_c = torch.from_numpy(label_vector[1])\n",
    "        img_c = img.copy()\n",
    "        img_c = cv2.flip(img_c,-1)\n",
    "        dataset.append((img_c, label_c))\n",
    "## 사람 etc\n",
    "for file_name in stop_list:\n",
    "    if file_name[-4:] != '.png':continue    \n",
    "    img = cv2.imread(DATAS_STOP+file_name)\n",
    "    img = img.reshape(3,224,224)\n",
    "    dataset.append((img, torch.from_numpy(label_vector[3])))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RATE = 0.2\n",
    "BATCH_SIZE = 8\n",
    "TEST_SET_NUM = int(len(dataset)*TEST_RATE)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - TEST_SET_NUM, TEST_SET_NUM])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "#     num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "#     num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoDrive(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.output_classes=4 # position_bool, people, x, y\n",
    "        self.model_up = self.making_transfer_model1()\n",
    "\n",
    "    \n",
    "    def making_transfer_model1(self):\n",
    "        model = torchvision.models.squeezenet1_1(pretrained=True)       \n",
    "        model.classifier=torch.nn.Sequential(\n",
    "            torch.nn.Dropout(p=0.5, inplace=True),\n",
    "            torch.nn.Conv2d(512, self.output_classes, kernel_size=(1,1), stride=(1,1)),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.AdaptiveAvgPool2d(output_size=(1,1)),\n",
    "            torch.nn.Flatten()\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "#     def making_transfer_model2(self):\n",
    "#         model = models.squeezenet1_0(pretrained=True)\n",
    "#         model.classifier=torch.nn.Sequential(\n",
    "# #             torch.nn.Dropout(p=0.5, inplace=True),\n",
    "# #             torch.nn.Linear(in_features=212992, out_features=self.unit_output, bias=True),\n",
    "# #             torch.nn.Mish(),\n",
    "#             torch.nn.Dropout(p=0.5, inplace=True),\n",
    "#             torch.nn.Conv2d(512, self.unit_output, kernel_size=(1,1), stride=(1,1)),\n",
    "#             torch.nn.ReLU(True),\n",
    "#             torch.nn.AdaptiveAvgPool2d(output_size=(1,1)),\n",
    "#             torch.nn.Flatten()\n",
    "#         )\n",
    "#         return model\n",
    "\n",
    "    def forward(self, up_img): # follow / to_position / line_num / loaded\n",
    "        # up_img = torch.from_numpy(up_img).float()\n",
    "        # down_img = torch.from_numpy(down_img).float()\n",
    "        x_up = self.model_up(up_img)\n",
    "        # x_down = self.model_down(down_img)\n",
    "        # follow = follow.unsqueeze(-1)\n",
    "        # to_position = to_position.unsqueeze(-1)\n",
    "        # line_num = line_num.unsqueeze(-1)\n",
    "        # loaded = loaded.unsqueeze(-1)\n",
    "        # x = torch.cat([follow,to_position, line_num, loaded, x_up, x_down], dim=-1)\n",
    "        # x = self.determine_model(x.float())\n",
    "        return x_up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "auto = AutoDrive()\n",
    "auto = auto.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "LEARNING_RATE = 1e-4 # 1e-3\n",
    "NUM_EPOCHS=100*1000\n",
    "optimizer = torch.optim.Adam(auto.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9), weight_decay=0.0005)\n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "BEST_MODEL_PATH = 'best_model_squeeze_down3.pth'\n",
    "\n",
    "criterion = torch.nn.SmoothL1Loss()\n",
    "\n",
    "d_time = datetime.datetime.now()\n",
    "folder_name = \"runs/\"+d_time.strftime(\"%Y%m%d%H%M%S\")\n",
    "os.mkdir(folder_name)\n",
    "writer = SummaryWriter(log_dir=folder_name)\n",
    "pre_test_loss = 10.\n",
    "EARLY_BIRD = 0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss=0.\n",
    "    test_loss=0.\n",
    "#     auto.train()\n",
    "    for up_img,labels in train_loader:\n",
    "#         print(up_img)\n",
    "#         up_img = normalize(up_img.float()).to(device=device)\n",
    "        up_img = up_img.float().to(device=device)\n",
    "        labels=labels.to(device);                \n",
    "        optimizer.zero_grad()\n",
    "        outputs = auto(up_img.float())\n",
    "#         print(\"outputs: \",outputs[-1], \"labels: \", labels[-1])\n",
    "#         loss = F.cross_entropy(outputs, labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss+=loss        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         scaler.scale(loss).backward()\n",
    "#         scaler.step(optimizer)\n",
    "#         scaler.update()\n",
    "        \n",
    "    \n",
    "    acc = 0.\n",
    "    acc0=acc1=acc2=0\n",
    "    count0=count1=count2=0\n",
    "    with torch.no_grad():\n",
    "        for up_img,labels in test_loader:\n",
    "#             up_img = normalize(up_img.float()).to(device=device);\n",
    "            up_img = up_img.float().to(device=device)\n",
    "            labels=labels.to(device);        1        \n",
    "            outputs = auto(up_img.float())\n",
    "    #         loss_position = F.cross_entropy(outputs[:,0], position_bool)\n",
    "    #         loss_people = F.cross_entropy(outputs[:,1], people)\n",
    "    #         loss_x = F.cross_entropy(outputs[:,2], x)\n",
    "    #         loss_y = F.cross_entropy(outputs[:,3], y)\n",
    "            loss =criterion(outputs, labels)\n",
    "            acc0 += sum(labels.argmax(-1)==0)\n",
    "            acc1 += sum(labels.argmax(-1)==1)\n",
    "            acc2 += sum(labels.argmax(-1)==2)\n",
    "            count0 += sum(outputs.argmax(-1)==0)\n",
    "            count1 += sum(outputs.argmax(-1)==1)\n",
    "            count2 += sum(outputs.argmax(-1)==2)\n",
    "                \n",
    "            acc += sum(outputs.argmax(-1)==labels.argmax(-1))\n",
    "            test_loss+=loss\n",
    "            \n",
    "#             print(\"outputs: \",outputs)\n",
    "#     print(f\"{epoch} TRAIN_LOSS: {train_loss.item()} TEST LOSS: {test_loss.item()}\")\n",
    "    writer.add_scalar(\"ACC\",acc.item()/len(test_dataset),epoch)\n",
    "    writer.add_scalar(\"TEST LOSS\",test_loss.item()/len(test_dataset),epoch)\n",
    "    # print(epoch, \"TRAIN_LOSS\",train_loss.item()/len(test_dataset),\"TEST LOSS\",test_loss.item()/len(test_dataset), 'ACC:', acc.item()/len(test_dataset))\n",
    "    # print(acc0.item(),count0.item(),\"  \", acc1.item(), count1.item(), \"  \", acc2.item(), count2.item())\n",
    "   \n",
    "#     print(\"outputs: \",outputs[-1], \"labels: \", labels[-1])\n",
    "    \n",
    "    if pre_test_loss>test_loss and epoch>50:\n",
    "        pre_test_loss= test_loss\n",
    "        torch.save(auto.state_dict(), BEST_MODEL_PATH)\n",
    "    if pre_test_loss<test_loss and epoch>50:\n",
    "        EARLY_BIRD +=1\n",
    "        if EARLY_BIRD >100:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "33b0c032e04388c0be1572b4c64e4f6e2fa9cda7ba5f9f285430d52a126a80b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('datavenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
