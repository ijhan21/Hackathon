{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개발환경\n",
    "- pytorch=1.10\n",
    "- opencv=4.5.4\n",
    "- numpy=1.21.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_a2c import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation dataset 경로 입력\n",
    "### 한 폴더에 png, npy 파일 같이 배치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_PATH='./test_image/A2C/'\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE = 'cpu'\n",
    "# W_SIZE = 600\n",
    "# H_SIZE = 400\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 준비 및 모델 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../test_image/A2C/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37689/3947456624.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile_list_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVALIDATION_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnpy_list_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpng_list_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../test_image/A2C/'"
     ]
    }
   ],
   "source": [
    "file_list_val = os.listdir(VALIDATION_PATH)\n",
    "npy_list_val = list()\n",
    "png_list_val = list()\n",
    "\n",
    "for name in file_list_val:\n",
    "    if name[-4:]=='.png':\n",
    "        png_list_val.append(name)\n",
    "    elif name[-4:]=='.npy':\n",
    "        npy_list_val.append(name)\n",
    "\n",
    "dataset_val = list()\n",
    "for name in png_list_val:\n",
    "    common_name = name[:-4]\n",
    "    npy_obj = np.load(VALIDATION_PATH+common_name+'.npy')\n",
    "    W_SIZE,H_SIZE = npy_obj.shape\n",
    "    # npy_obj = cv2.resize(npy_obj, (W_SIZE,H_SIZE)).reshape(1,H_SIZE,W_SIZE)*255\n",
    "    npy_obj = cv2.resize(npy_obj, (W_SIZE,H_SIZE)).reshape(1,H_SIZE,W_SIZE)*255\n",
    "    png_obj = cv2.imread(VALIDATION_PATH+common_name+'.png', 0)\n",
    "    png_obj = cv2.resize(png_obj, (W_SIZE,H_SIZE)).reshape(1,H_SIZE,W_SIZE)\n",
    "    dataset_val.append((png_obj, npy_obj))\n",
    "\n",
    "test_dataset = dataset_val\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "BEST_MODEL_PATH = 'best_model_A2C.pth'\n",
    "unet = DoubleUNet(1,1).to(DEVICE)\n",
    "unet.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
    "unet.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validation set predict\n",
    "### 종합된 DSC , JI 수치 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76663040d384d06a7eeda515f9605cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best A2C DSC: 0.9361499571119493 JI:  0.8799642048897868\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TP_collect = list()\n",
    "LABEL_TRUE_SUM_collect = list()\n",
    "PREDICTI_TRUE_SUM_collect = list()\n",
    "outputs = list()\n",
    "for img, label in tqdm(test_loader):\n",
    "    img = img.to(DEVICE)\n",
    "    label_test = label.float().to(DEVICE)\n",
    "                \n",
    "    outputs_test,  adap_outputs, adap_label = unet(img.float(), label_test)\n",
    "    outputs.append(outputs_test)\n",
    "\n",
    "\n",
    "    # DSC = 2*TP/(2TP+FP+FN)\n",
    "    # JI = DICE/(2-DICE)       \n",
    "    outputs_test_for_grid = torch.round(unet.get_output())\n",
    "    cal_outputs_test_for_grid = outputs_test_for_grid.int()\n",
    "\n",
    "    cal_label_test = label_test.int()\n",
    "    cal_label_test = torch.round(cal_label_test/255.).int()\n",
    "    TP_collect.append(torch.sum(cal_outputs_test_for_grid & cal_label_test))\n",
    "    LABEL_TRUE_SUM_collect.append(torch.sum(cal_label_test))\n",
    "    PREDICTI_TRUE_SUM_collect.append(torch.sum(cal_outputs_test_for_grid))\n",
    "\n",
    "TP = np.sum(TP_collect)\n",
    "LABEL_TRUE_SUM = np.sum(LABEL_TRUE_SUM_collect)\n",
    "PREDICTI_TRUE_SUM = np.sum(PREDICTI_TRUE_SUM_collect)\n",
    "\n",
    "\n",
    "DSC = 2*TP/(LABEL_TRUE_SUM+PREDICTI_TRUE_SUM)\n",
    "JI = DSC/(2-DSC)\n",
    "pre_test_loss = DSC\n",
    "\n",
    "print(' Best A2C DSC:',DSC.item(), 'JI: ', JI.item())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9307834ef4db415b79a581390e89b9869bb0225797b37023425526a129547564"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('torch': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
